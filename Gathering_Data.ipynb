{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import requests\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "def get_and_save_sub_images(subreddit, date, min_votes):\n",
    "    '''saves images from the given subreddit since date (d/m/y) with >= min_votes in a folder named subreddit_[day]_month'''\n",
    "    \n",
    "    urls = get_urls(subreddit, date, min_votes)\n",
    "    today = datetime.datetime.today()\n",
    "    month,day = today.month, today.day\n",
    "    for fol in ['train','test','validation']:\n",
    "        folder = \"images/{}/{}_{}_{}/\".format(fol,subreddit, month, day)\n",
    "        os.mkdir(folder)\n",
    "    folder+='/'\n",
    "    print(\"saving {} images to {} \".format(len(urls),folder))\n",
    "    i = 0\n",
    "    for ind, url in enumerate(urls):\n",
    "        \n",
    "        if i%10 == 9:\n",
    "            fol = 'test'\n",
    "        elif i%10 == 8:\n",
    "            fol = 'validation'\n",
    "        else:\n",
    "            fol = 'train'\n",
    "            \n",
    "        folder = \"images/{}/{}_{}_{}/\".format(fol,subreddit, month, day)\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.content:\n",
    "                img = Image.open(io.BytesIO(response.content))\n",
    "                name = \"image{}{}\".format(ind,url[-4:])\n",
    "                img.save(folder+name)\n",
    "                i+=1\n",
    "        except:\n",
    "            continue\n",
    "        if i%100 == 0:\n",
    "            print(\"saved {} images from r/{}\".format(i,subreddit))\n",
    "    print(\"done with /r/{}\".format(subreddit))\n",
    "\n",
    "def get_urls(subreddit,date,min_votes):\n",
    "    ''' returns a list of urls of images posted on the sub since date that have >= min_votes upvotes'''\n",
    "    current_time = time.time()\n",
    "    start_time = time.mktime(datetime.datetime.strptime(date, \"%d/%m/%Y\").timetuple())\n",
    "    urls = []\n",
    "    reddit = praw.Reddit(client_secret = os.environ['REDDIT_API_SECRET'],\n",
    "                     client_id = os.environ['REDDIT_API_ID'] ,\n",
    "                     user_agent = 'gathering data by /u/GougeC')\n",
    "    i = 0\n",
    "    for post in reddit.subreddit(subreddit).submissions(start_time,current_time):\n",
    "        if post.ups >= min_votes:\n",
    "            url = post.url\n",
    "            if url[-4:] in ('.png' ,'.jpg'):\n",
    "                urls.append(url)\n",
    "                i+=1\n",
    "                if i%100 ==0:\n",
    "                    print(\"got {} urls\".format(i))\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 100 urls\n",
      "got 200 urls\n",
      "got 300 urls\n",
      "got 400 urls\n",
      "got 500 urls\n",
      "got 600 urls\n",
      "got 700 urls\n",
      "got 800 urls\n",
      "got 900 urls\n",
      "got 1000 urls\n",
      "got 1100 urls\n",
      "got 1200 urls\n",
      "got 1300 urls\n",
      "got 1400 urls\n",
      "got 1500 urls\n",
      "got 1600 urls\n",
      "got 1700 urls\n",
      "got 1800 urls\n",
      "got 1900 urls\n",
      "got 2000 urls\n",
      "got 2100 urls\n",
      "got 2200 urls\n",
      "got 2300 urls\n",
      "got 2400 urls\n",
      "got 2500 urls\n",
      "got 2600 urls\n",
      "got 2700 urls\n",
      "got 2800 urls\n",
      "got 2900 urls\n",
      "got 3000 urls\n",
      "got 3100 urls\n",
      "got 3200 urls\n",
      "got 3300 urls\n",
      "got 3400 urls\n",
      "got 3500 urls\n",
      "got 3600 urls\n",
      "got 3700 urls\n",
      "got 3800 urls\n",
      "got 3900 urls\n",
      "got 4000 urls\n",
      "got 4100 urls\n",
      "got 4200 urls\n",
      "got 4300 urls\n",
      "got 4400 urls\n",
      "got 4500 urls\n",
      "got 4600 urls\n",
      "saving 4668 images to images/validation/earthporn_3_9// \n",
      "saved 100 images from r/earthporn\n",
      "saved 200 images from r/earthporn\n",
      "saved 300 images from r/earthporn\n",
      "saved 400 images from r/earthporn\n",
      "saved 500 images from r/earthporn\n",
      "saved 600 images from r/earthporn\n",
      "saved 700 images from r/earthporn\n",
      "saved 800 images from r/earthporn\n",
      "saved 900 images from r/earthporn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py:2438: DecompressionBombWarning: Image size (93153600 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 1000 images from r/earthporn\n",
      "saved 1100 images from r/earthporn\n",
      "saved 1200 images from r/earthporn\n",
      "saved 1300 images from r/earthporn\n",
      "saved 1400 images from r/earthporn\n",
      "saved 1500 images from r/earthporn\n",
      "saved 1600 images from r/earthporn\n",
      "saved 1700 images from r/earthporn\n",
      "saved 1800 images from r/earthporn\n",
      "saved 1900 images from r/earthporn\n",
      "saved 2000 images from r/earthporn\n",
      "saved 2100 images from r/earthporn\n",
      "saved 2200 images from r/earthporn\n",
      "saved 2300 images from r/earthporn\n",
      "saved 2400 images from r/earthporn\n",
      "saved 2500 images from r/earthporn\n",
      "saved 2600 images from r/earthporn\n",
      "saved 2700 images from r/earthporn\n",
      "saved 2800 images from r/earthporn\n",
      "saved 2900 images from r/earthporn\n",
      "saved 3000 images from r/earthporn\n",
      "saved 3100 images from r/earthporn\n",
      "saved 3200 images from r/earthporn\n",
      "saved 3300 images from r/earthporn\n",
      "saved 3400 images from r/earthporn\n",
      "saved 3500 images from r/earthporn\n",
      "saved 3600 images from r/earthporn\n",
      "saved 3700 images from r/earthporn\n",
      "saved 3800 images from r/earthporn\n",
      "saved 3900 images from r/earthporn\n",
      "saved 4000 images from r/earthporn\n",
      "saved 4100 images from r/earthporn\n",
      "saved 4200 images from r/earthporn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py:2438: DecompressionBombWarning: Image size (98130452 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 4300 images from r/earthporn\n",
      "saved 4400 images from r/earthporn\n",
      "saved 4500 images from r/earthporn\n",
      "saved 4600 images from r/earthporn\n",
      "done with /r/earthporn\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('images')\n",
    "for fol in ['train','test','validation']:\n",
    "    os.mkdir('images/{}'.format(fol))\n",
    "\n",
    "get_and_save_sub_images('earthporn','01/01/2017',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 100 urls\n",
      "got 200 urls\n",
      "got 300 urls\n",
      "got 400 urls\n",
      "got 500 urls\n",
      "got 600 urls\n",
      "got 700 urls\n",
      "got 800 urls\n",
      "got 900 urls\n",
      "got 1000 urls\n",
      "got 1100 urls\n",
      "got 1200 urls\n",
      "got 1300 urls\n",
      "got 1400 urls\n",
      "saving 1408 images to images/validation/cityporn_3_9// \n",
      "saved 100 images from r/cityporn\n",
      "saved 200 images from r/cityporn\n",
      "saved 300 images from r/cityporn\n",
      "saved 400 images from r/cityporn\n",
      "saved 500 images from r/cityporn\n",
      "saved 600 images from r/cityporn\n",
      "saved 700 images from r/cityporn\n",
      "saved 800 images from r/cityporn\n",
      "saved 900 images from r/cityporn\n",
      "saved 1000 images from r/cityporn\n",
      "saved 1100 images from r/cityporn\n",
      "saved 1200 images from r/cityporn\n",
      "saved 1300 images from r/cityporn\n",
      "done with /r/cityporn\n"
     ]
    }
   ],
   "source": [
    "get_and_save_sub_images('cityporn','01/01/2017',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
