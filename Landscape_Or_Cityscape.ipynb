{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landscape or Cityscape?\n",
    "\n",
    "The idea behind this notebook is to test out various CNNs to determine which networks are best suited to determining if an picture is an image of a city or an image of nature. My data sources for this experiment are the subreddits r/earthporn and r/cityporn. I chose these subreddits as they are focused and fairly strictly moderated. Each contains only aestetically pleasing pictures of landscapes and cityscapes respectively. I took all the directly linked images from these subreddits since 1/1/17 that have over a certain threshold of upvotes, which gave me a few thousand images that are almost entirely either a picture of a natural landscape or a picture of a cityscape\n",
    "\n",
    "I will use keras' implementation of VGG16, ResNet50 and InceptionV3 to extract features from the images, and then I will contruct a CNN of my own design and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keras specific imports\n",
    "from keras import Model, Input\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.applications import VGG16,vgg16\n",
    "from keras.applications import ResNet50, resnet50\n",
    "from keras.applications import InceptionV3, inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_for_vgg(path):\n",
    "    img = image.load_img(path, target_size = (224, 224) )\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x = vgg16.preprocess_input(x, mode='tf')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG = VGG16(weights = 'imagenet', include_top = False, input_shape= (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(base_layers):\n",
    "    X = base_layers.output\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(100, activation = 'relu',name = '1')(X)\n",
    "    predictions = Dense(2 , activation = 'softmax',name = '2')(X)\n",
    "    print(predictions.shape)\n",
    "    model = Model(inputs = base_layers.inputs, outputs = predictions)\n",
    "    for layer in base_layers.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(shear_range= 0.2,\n",
    "                                    zoom_range= 0.2,\n",
    "                                    horizontal_flip= True,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range = 0.2,\n",
    "                                    preprocessing_function= (lambda x: x/127.5 - 1))                                           \n",
    "\n",
    "train_generator = data_gen.flow_from_directory('./images', target_size= (224,224), class_mode= 'categorical')\n",
    "\n",
    "vgg_model = create_model(VGG)\n",
    "\n",
    "vgg_model.compile(optimizer='rmsprop',loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_model.fit_generator(data_generator, epochs=10, steps_per_epoch= 500,\n",
    "                        use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
